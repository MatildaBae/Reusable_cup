# -*- coding: utf-8 -*-
"""MCLP_1003.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5ilyEi3Rxush2yrIUmzpeT6M26xIuVx
"""

# Commented out IPython magic to ensure Python compatibility.
# from geoband.API import *
from tqdm import tqdm
import pandas as pd
import numpy as np
import geopandas as gpd
import seaborn as sns
import json
import random
import matplotlib.pylab as plt
# %matplotlib inline

# MCLP를 위한 선형계획법 툴
from pulp import *

# 시각화 툴 : Pydeck
import pydeck as pdk

# 지리 데이터 전처리 툴 : Shapely
import shapely.speedups
shapely.speedups.enable()
from shapely.ops import unary_union
from shapely.geometry import Point, MultiLineString, mapping, shape

mapbox_key = 'pk.eyJ1IjoiY3V0aWVueSIsImEiOiJja3J1ZTJrMTYxMG51MnVtd21iaGw5bjZuIn0.1W_w68zfsaE-2bc6QAW1nA'

import warnings
warnings.filterwarnings(action='ignore')

pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 200)

pip install pulp

data = pd.read_excel('./data/DAB_data.xlsx')
data.head()

data['score'] = np.random.rand(len(data))

"""### 후보지, 수요지 = 전체 카페 데이터  
1. 카페별로 score 구하기 -> 스타벅스 요인분석으로 weight나와서 구할 것  
2. descending order로 나열  
3. score이 최대인 카페부터 GAAS MCLP  => 해당 코드에서 진행할 부분
"""

data.columns

# 카페명, 위도, 경도, score
data = data[['branchnm','Latitude','Longitude','score']]
data.sort_values('score', ascending = False, inplace = True) # score 내림차순 정렬
data.reset_index(inplace = True)

data = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data.Latitude, data.Longitude))

data.head()

# 카페끼리의 거리
# 카페 간에 최소 거리 제약
r = np.empty((len(data), len(data)))
for i in range(len(data)):
        p1, p2 = (data.loc[i,'Latitude'],data.loc[i,'Longitude']), (data.loc[])
    for j in range(len(data)):
        r[i][j] = haversine.haversine()
# for i in range(len(data)):
#     data_i = data.geometry[i]
#     r[i] = [ data_i.distance(data_j) for data_j in data.geometry]
r.shape

haversine.haversine(a,b)

I = data.index.values
J = data.index.values
S = 300 # Coverage 거리
min_dist = 50
# a = data.weights.values
P = 100 # 설치예정 시설물 수

N = [[j for j in J if r[i][j] < S] for i in I]
R = [[int(r[data_i][data_j] < min_dist) for data_j in J ] for data_i in J]

r

R

base = pdk.Layer(
    'PolygonLayer', # 사용할 Layer 타입
    data, # 시각화에 쓰일 데이터프레임
    get_polygon='coordinates', # geometry 정보를 담고있는 컬럼 이름
    get_fill_color='[255, 255, 255]', # 각 데이터 별 rgb 또는 rgba 값 (0~255)
    opacity = 0.005
)

# Compute the sets Ni
# NB: this will be a list in which each item is a list of nodes
# within the threshold distance of the i'th node
N = [[j for j in J if d[i][j] < S] for i in I]
R = [[int(r[station_i][station_j] < min_dist) for station_j in J ] for station_i in J]
# Formulate optimisation

prob = LpProblem("MCLP", LpMaximize)
x = LpVariable.dicts("x", J, lowBound=0, upBound=1, cat='Integer')
y = LpVariable.dicts("y", I, lowBound=0, upBound=1, cat='Integer')

# Objective
prob += lpSum([a[i]*y[i] for i in I])

# Constraints
for i in I:
    prob += lpSum([x[j] for j in N[i]]) >= y[i]
for j in J:
    prob += lpSum([x[rr] for rr in R[j]]) <= 1


prob += lpSum([x[j] for j in J]) == P

# Solve problem
prob.solve()

x_soln = np.array([x[j].varValue for j in J])

# And print some output
print (("Status:"), LpStatus[prob.status])
print ("Weight Covered is = ", value(prob.objective))
print ("x = ", x_soln)